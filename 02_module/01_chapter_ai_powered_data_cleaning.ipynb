{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Chapter 1: AI-Powered Data Cleaning\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "- Understand why scraped data needs cleaning and standardization\n",
    "- Create traditional parsing functions for salary data\n",
    "- Set up PydanticAI with Google Gemini for intelligent data processing\n",
    "- Build AI-powered functions that outperform traditional rule-based approaches\n",
    "- Save reusable data cleaning functions to your workshoplib\n",
    "\n",
    "---\n",
    "\n",
    "## Module 2: From Messy Data to Clean Insights\n",
    "\n",
    "In Module 1, we extracted valuable job data from Indeed.com. But real-world data is never clean out of the box. Let's examine what we collected and see why we need data cleaning.\n",
    "\n",
    "### The Reality of Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"data\").absolute()\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load OEWS data\n",
    "bls_file = Path(\"../01_module/data/bls_jobs_metro_area_2024.csv\")\n",
    "oews_df = pd.read_csv(bls_file)\n",
    "\n",
    "# Load scraped Indeed data\n",
    "scraped_file_paths = list(Path(\"../01_module/data\").glob(\"scraped_indeed_*.csv\"))\n",
    "\n",
    "dataframes = [pd.read_csv(file) for file in scraped_file_paths]\n",
    "indeed_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(f\"ðŸ“Š Loaded {len(scraped_file_paths)} scraped files with {len(indeed_df)} total jobs\")\n",
    "\n",
    "print(\"\\n=== INDEED DATA SAMPLE ===\")\n",
    "print(f\"Shape: {indeed_df.shape}\")\n",
    "print(f\"Columns: {list(indeed_df.columns)}\")\n",
    "print(\"\\nFirst few salary values:\")\n",
    "for i, salary in enumerate(indeed_df[\"salary\"].head()):\n",
    "    print(f\"  {i + 1}. '{salary}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "> **Learner Challenge**: Examine the salary values in your scraped data. What patterns do you notice? What formats would be challenging to parse with traditional code? Make a list of at least 3 different salary formats you observe.\n",
    "\n",
    "---\n",
    "\n",
    "## Traditional Approach: Manual Salary Parsing\n",
    "\n",
    "Let's start by building a traditional function to parse salary data. This will help us appreciate why AI is so powerful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _extract_numbers(text: str) -> list[float]:\n",
    "    \"\"\"Extracts all numerical values from a string, handling 'K' notation.\"\"\"\n",
    "\n",
    "    # First, handle 'k' notation (e.g., \"80K\", \"120k\") by converting to full numbers\n",
    "    text = re.sub(r\"(\\d+)k\", lambda m: str(int(m.group(1)) * 1000), text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Next, find all remaining numbers, including those with commas\n",
    "    numbers_as_strings = re.findall(r\"\\$?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\", text)\n",
    "\n",
    "    if not numbers_as_strings:\n",
    "        return []\n",
    "\n",
    "    # Convert all found strings to floats, handling potential errors\n",
    "    try:\n",
    "        return [float(num.replace(\",\", \"\")) for num in numbers_as_strings]\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "\n",
    "def _calculate_min_max(numbers: list[float], text: str) -> tuple[Optional[float], Optional[float]]:\n",
    "    \"\"\"Determines the min and max salary from a list of numbers.\"\"\"\n",
    "\n",
    "    if len(numbers) >= 2:\n",
    "        return min(numbers), max(numbers)\n",
    "    elif len(numbers) == 1:\n",
    "        # If text indicates \"up to\", this single number is the max\n",
    "        if \"up to\" in text or \"up-to\" in text:\n",
    "            return None, numbers[0]\n",
    "        # Otherwise, the single number is both the min and max\n",
    "        else:\n",
    "            return numbers[0], numbers[0]\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def _parse_single_salary(salary_string: str) -> dict:\n",
    "    \"\"\"\n",
    "    Orchestrates the parsing of a single salary string using helper functions.\n",
    "    \"\"\"\n",
    "    # Handle empty or non-string inputs first\n",
    "    if pd.isna(salary_string) or not str(salary_string).strip():\n",
    "        return {\"min_salary\": None, \"max_salary\": None, \"salary_type\": \"unknown\"}\n",
    "\n",
    "    text = str(salary_string).lower().strip()\n",
    "\n",
    "    # Check for non-numeric terms first\n",
    "    if any(word in text for word in [\"competitive\", \"negotiable\", \"commission\", \"doe\"]):\n",
    "        return {\"min_salary\": None, \"max_salary\": None, \"salary_type\": \"non_numeric\"}\n",
    "\n",
    "    # Use helpers to get numbers and determine min/max\n",
    "    numbers = _extract_numbers(text)\n",
    "    min_salary, max_salary = _calculate_min_max(numbers, text)\n",
    "\n",
    "    # Determine the salary type and convert if necessary\n",
    "    if \"hour\" in text or \"/hr\" in text:\n",
    "        salary_type = \"hourly_converted\"\n",
    "        # Assume 40 hours/week, 52 weeks/year for annual conversion\n",
    "        annualization_factor = 40 * 52\n",
    "        min_salary = min_salary * annualization_factor if min_salary else None\n",
    "        max_salary = max_salary * annualization_factor if max_salary else None\n",
    "    else:\n",
    "        salary_type = \"annual\"\n",
    "\n",
    "    # If no numbers were successfully parsed, classify as unknown\n",
    "    if min_salary is None and max_salary is None:\n",
    "        salary_type = \"unknown\"\n",
    "\n",
    "    return {\"min_salary\": min_salary, \"max_salary\": max_salary, \"salary_type\": salary_type}\n",
    "\n",
    "\n",
    "# --- 4. Public-Facing Batch Processing Function ---\n",
    "def traditional_parse_salaries(salary_list: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Parses a list of salary strings by applying the parsing logic to each item.\n",
    "\n",
    "    Args:\n",
    "        salary_list: A list of raw salary text strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing parsed salary information.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension for a clean and efficient way to process the batch\n",
    "    return [_parse_single_salary(s) for s in salary_list]\n",
    "\n",
    "\n",
    "# --- 5. Test the Updated Batch Function ---\n",
    "test_salaries = [\n",
    "    \"$50,000 - $70,000 per year\",\n",
    "    \"$25 per hour\",\n",
    "    \"Up to $80K\",\n",
    "    \"Competitive salary\",\n",
    "    \"$120k annually\",\n",
    "    None,\n",
    "    \"Varies based on experience\",\n",
    "]\n",
    "\n",
    "print(\"=== TESTING TRADITIONAL BATCH SALARY PARSING ===\")\n",
    "parsed_results = traditional_parse_salaries(test_salaries)\n",
    "\n",
    "for original, parsed in zip(test_salaries, parsed_results):\n",
    "    print(f\"Input: '{original}'\")\n",
    "    print(f\"Output: {parsed}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setting Up AI Tools: PydanticAI + Google Gemini\n",
    "\n",
    "Now let's set up AI tools that can handle salary parsing much more intelligently.\n",
    "\n",
    "### Getting Your Google API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Check if we have a Google API key\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"ðŸ”‘ You need a Google API key to use Gemini!\")\n",
    "    print(\"\\nTo get your free API key:\")\n",
    "    print(\"1. Go to https://aistudio.google.com/app/apikey\")\n",
    "    print(\"2. Sign in with your Google account\")\n",
    "    print(\"3. Click 'Create API Key'\")\n",
    "    print(\"4. Copy the key and add it to your .env file:\")\n",
    "    print(\"   GOOGLE_API_KEY=your_key_here\")\n",
    "    print(\"\\nAfter adding the key, restart the notebook.\")\n",
    "else:\n",
    "    print(\"âœ… Google API key found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Installing and Configuring PydanticAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.google import GoogleModel\n",
    "from pydantic_ai.providers.google import GoogleProvider\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "provider = GoogleProvider(api_key=API_KEY)\n",
    "model = GoogleModel(\"gemini-1.5-flash\", provider=provider)\n",
    "\n",
    "\n",
    "# Test our AI setup with a simple example\n",
    "class TestResponse(BaseModel):\n",
    "    message: str\n",
    "    number: int\n",
    "\n",
    "\n",
    "test_agent = Agent(\n",
    "    model,\n",
    "    output_type=TestResponse,\n",
    "    system_prompt=\"You are a helpful assistant. Return a friendly message and a random number.\",\n",
    ")\n",
    "\n",
    "result = test_agent.run_sync(\"Say hello and give me a number between 1 and 100\")\n",
    "print(f\"ðŸ¤– AI Test Result: {result.output.message} (Number: {result.output.number})\")\n",
    "print(\"âœ… AI setup successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AI-Powered Salary Parsing\n",
    "\n",
    "Now let's create an AI function that can parse salaries much more intelligently than our traditional approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "SalaryType = Literal[\"annual\", \"hourly_converted\", \"non_numeric\", \"unknown\"]\n",
    "\n",
    "\n",
    "# This Pydantic model ensures the AI's response is always in a clean, predictable format.\n",
    "class SalaryInfo(BaseModel):\n",
    "    min_salary: Optional[float]\n",
    "    max_salary: Optional[float]\n",
    "    salary_type: SalaryType\n",
    "    confidence: int = Field(\n",
    "        ..., description=\"A 1-10 confidence score (1 = not confident, 10 = very confident)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SalaryParsingResults(BaseModel):\n",
    "    salaries: list[SalaryInfo] = Field(\n",
    "        ..., description=\"A list of parsed salary information objects.\"\n",
    "    )\n",
    "\n",
    "\n",
    "salary_agent = Agent(\n",
    "    \"gemini-1.5-flash\",\n",
    "    output_type=SalaryParsingResults,\n",
    "    system_prompt=\"\"\"\n",
    "    You are an expert at parsing a LIST of salary information strings from job postings.\n",
    "    Process each item from the input list and return a corresponding list of structured objects.\n",
    "\n",
    "    Rules:\n",
    "        1. Convert hourly rates to annual amounts. Assume a standard 40-hour work week and 52 weeks per year.\n",
    "        2. Handle salary ranges (e.g., \"$50K - $70K\") by setting both min_salary and max_salary.\n",
    "        3. Handle single values (e.g., \"Up to $80,000\" or \"$25/hour\") appropriately.\n",
    "        4. For non-numeric salaries (e.g., \"Competitive salary\"), set salary_type to 'non_numeric' and salaries to null.\n",
    "        5. Always provide a confidence score from 1 (not confident) to 10 (very confident).\n",
    "        6. If the input is empty, nonsensical, or unparsable, set salary_type to 'unknown'.\n",
    "\n",
    "    Example Input List:\n",
    "    - \"$25 an hour\"\n",
    "    - \"$50K - $70K\"\n",
    "\n",
    "    Example Output: A JSON object containing a list with two salary info objects.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "def ai_parse_salaries(salary_list: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Uses the AI agent to parse a list of salary strings in a single batch operation.\n",
    "\n",
    "    Args:\n",
    "        salary_list: A list of raw salary text strings from job postings.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing parsed salary information.\n",
    "    \"\"\"\n",
    "    # Handle empty or null input list.\n",
    "    if not salary_list:\n",
    "        return []\n",
    "\n",
    "    # Format the list of strings into a single prompt for the AI.\n",
    "    formatted_list = \"\\n\".join(f\"- '{s}'\" for s in salary_list if pd.notna(s) and str(s).strip())\n",
    "    prompt = f\"Parse the following list of salary strings:\\n{formatted_list}\"\n",
    "\n",
    "    try:\n",
    "        # Make a single synchronous call to the agent for the entire batch.\n",
    "        result = salary_agent.run_sync(prompt)\n",
    "\n",
    "        # Convert the list of Pydantic models from the result into a list of dictionaries.\n",
    "        return [s.model_dump() for s in result.output.salaries]\n",
    "    except Exception as e:\n",
    "        print(f\"AI batch parsing error: {e}\")\n",
    "        # Return a list of error objects matching the input length\n",
    "        return [\n",
    "            {\"min_salary\": None, \"max_salary\": None, \"salary_type\": \"error\", \"confidence\": 1}\n",
    "        ] * len(salary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_salaries = [\n",
    "    \"$55,000 - $65,000 a year\",\n",
    "    \"$30 an hour\",\n",
    "    \"Up to $120k\",\n",
    "    \"Competitive Salary\",\n",
    "    \"From $95,000 a year\",\n",
    "    None,\n",
    "    \"Varies\",\n",
    "]\n",
    "\n",
    "print(\"=== TESTING BATCH AI SALARY PARSING ===\")\n",
    "parsed_results = ai_parse_salaries(test_salaries)\n",
    "\n",
    "# Display the results, pairing each input with its corresponding output.\n",
    "for original, parsed in zip(test_salaries, parsed_results):\n",
    "    print(f\"Input: '{original}'\")\n",
    "    print(f\"AI Output: {parsed}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Comparing Traditional vs AI Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Test Data ---\n",
    "test_salaries = [\n",
    "    \"$55,000 - $65,000 a year\",\n",
    "    \"$30 an hour\",\n",
    "    \"Up to $120k\",\n",
    "    \"Competitive Salary\",\n",
    "    \"From $95,000 a year\",\n",
    "    None,\n",
    "    \"Varies\",\n",
    "]\n",
    "\n",
    "# Process the entire list with the traditional, rule-based function.\n",
    "all_trad_results = traditional_parse_salaries(test_salaries)\n",
    "\n",
    "# Process the entire list with the AI-powered function.\n",
    "all_ai_results = ai_parse_salaries(test_salaries)\n",
    "\n",
    "print(\"=== TRADITIONAL vs AI COMPARISON ===\")\n",
    "print(f\"{'Salary Input':<35} | {'Traditional Result':<25} | {'AI Result':<25} | {'AI Confidence'}\")\n",
    "print(\"-\" * 115)\n",
    "\n",
    "# Use zip() to iterate through the original inputs and both sets of results simultaneously.\n",
    "for salary, trad_result, ai_result in zip(test_salaries, all_trad_results, all_ai_results):\n",
    "    # Format the traditional result for clean printing.\n",
    "    trad_min = trad_result.get(\"min_salary\")\n",
    "    trad_max = trad_result.get(\"max_salary\")\n",
    "    trad_summary = f\"${trad_min or 0:,.0f} - ${trad_max or 0:,.0f}\"\n",
    "\n",
    "    # Format the AI result for clean printing.\n",
    "    ai_min = ai_result.get(\"min_salary\")\n",
    "    ai_max = ai_result.get(\"max_salary\")\n",
    "    ai_summary = f\"${ai_min or 0:,.0f} - ${ai_max or 0:,.0f}\"\n",
    "\n",
    "    # Handle display for non-numeric types for better readability.\n",
    "    if trad_result.get(\"salary_type\") in [\"non_numeric\", \"unknown\"]:\n",
    "        trad_summary = f\"({trad_result.get('salary_type')})\"\n",
    "\n",
    "    if ai_result.get(\"salary_type\") in [\"non_numeric\", \"unknown\", \"error\"]:\n",
    "        ai_summary = f\"({ai_result.get('salary_type')})\"\n",
    "\n",
    "    # Ensure the original salary string is not None for printing.\n",
    "    salary_str = str(salary) if salary is not None else \"None\"\n",
    "\n",
    "    print(\n",
    "        f\"{salary_str:<35} | {trad_summary:<25} | {ai_summary:<25} | {ai_result.get('confidence', 'N/A')}/10\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "> **Learner Challenge**: Add 2-3 additional salary strings to the test data that you think might be challenging to parse. Try some edge cases like \"DOE (Depends on Experience)\" or \"$15-20/hr + tips\". Compare how the traditional vs AI approaches handle these cases.\n",
    "\n",
    "---\n",
    "\n",
    "## Saving Our Functions to WorkshopLib\n",
    "\n",
    "Let's save our salary parsing functions to our `workshoplib` so we can use them in other modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../workshoplib/src/workshoplib/janitor.py\n",
    "\n",
    "\"\"\"\n",
    "Data cleaning and parsing utilities for the workshop.\n",
    "\n",
    "This module contains functions for cleaning messy real-world data,\n",
    "including both traditional rule-based approaches and AI-powered solutions.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "def _extract_numbers(text: str) -> list[float]:\n",
    "    \"\"\"Extracts all numerical values from a string, handling 'K' notation.\"\"\"\n",
    "\n",
    "    # First, handle 'k' notation (e.g., \"80K\", \"120k\") by converting to full numbers\n",
    "    text = re.sub(r'(\\d+)k', lambda m: str(int(m.group(1)) * 1000), text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Next, find all remaining numbers, including those with commas\n",
    "    numbers_as_strings = re.findall(r'\\$?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text)\n",
    "\n",
    "    if not numbers_as_strings:\n",
    "        return []\n",
    "\n",
    "    # Convert all found strings to floats, handling potential errors\n",
    "    try:\n",
    "        return [float(num.replace(',', '')) for num in numbers_as_strings]\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def _calculate_min_max(numbers: list[float], text: str) -> tuple[Optional[float], Optional[float]]:\n",
    "    \"\"\"Determines the min and max salary from a list of numbers.\"\"\"\n",
    "\n",
    "    if len(numbers) >= 2:\n",
    "        return min(numbers), max(numbers)\n",
    "    elif len(numbers) == 1:\n",
    "        # If text indicates \"up to\", this single number is the max\n",
    "        if 'up to' in text or 'up-to' in text:\n",
    "            return None, numbers[0]\n",
    "        # Otherwise, the single number is both the min and max\n",
    "        else:\n",
    "            return numbers[0], numbers[0]\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def _parse_single_salary(salary_string: str) -> dict:\n",
    "    \"\"\"\n",
    "    Orchestrates the parsing of a single salary string using helper functions.\n",
    "    \"\"\"\n",
    "    # Handle empty or non-string inputs first\n",
    "    if pd.isna(salary_string) or not str(salary_string).strip():\n",
    "        return {'min_salary': None, 'max_salary': None, 'salary_type': 'unknown'}\n",
    "\n",
    "    text = str(salary_string).lower().strip()\n",
    "\n",
    "    # Check for non-numeric terms first\n",
    "    if any(word in text for word in ['competitive', 'negotiable', 'commission', 'doe']):\n",
    "        return {'min_salary': None, 'max_salary': None, 'salary_type': 'non_numeric'}\n",
    "\n",
    "    # Use helpers to get numbers and determine min/max\n",
    "    numbers = _extract_numbers(text)\n",
    "    min_salary, max_salary = _calculate_min_max(numbers, text)\n",
    "\n",
    "    # Determine the salary type and convert if necessary\n",
    "    if 'hour' in text or '/hr' in text:\n",
    "        salary_type = 'hourly_converted'\n",
    "        # Assume 40 hours/week, 52 weeks/year for annual conversion\n",
    "        annualization_factor = 40 * 52\n",
    "        min_salary = min_salary * annualization_factor if min_salary else None\n",
    "        max_salary = max_salary * annualization_factor if max_salary else None\n",
    "    else:\n",
    "        salary_type = 'annual'\n",
    "\n",
    "    # If no numbers were successfully parsed, classify as unknown\n",
    "    if min_salary is None and max_salary is None:\n",
    "        salary_type = 'unknown'\n",
    "\n",
    "    return {\n",
    "        'min_salary': min_salary,\n",
    "        'max_salary': max_salary,\n",
    "        'salary_type': salary_type\n",
    "    }\n",
    "\n",
    "def traditional_parse_salaries(salary_list: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Parses a list of salary strings by applying the parsing logic to each item.\n",
    "\n",
    "    Args:\n",
    "        salary_list: A list of raw salary text strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing parsed salary information.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension for a clean and efficient way to process the batch\n",
    "    return [_parse_single_salary(s) for s in salary_list]\n",
    "\n",
    "SalaryType = Literal['annual', 'hourly_converted', 'non_numeric', 'unknown']\n",
    "\n",
    "# This Pydantic model ensures the AI's response is always in a clean, predictable format.\n",
    "class SalaryInfo(BaseModel):\n",
    "    min_salary: Optional[float]\n",
    "    max_salary: Optional[float]\n",
    "    salary_type: SalaryType\n",
    "    confidence: int = Field(..., description=\"A 1-10 confidence score (1 = not confident, 10 = very confident)\")\n",
    "\n",
    "\n",
    "class SalaryParsingResults(BaseModel):\n",
    "    salaries: list[SalaryInfo] = Field(..., description=\"A list of parsed salary information objects.\")\n",
    "\n",
    "_salary_agent = Agent(\n",
    "    'gemini-1.5-flash',\n",
    "    output_type=SalaryParsingResults,\n",
    "    system_prompt=\"\"\"\n",
    "    You are an expert at parsing a LIST of salary information strings from job postings.\n",
    "    Process each item from the input list and return a corresponding list of structured objects.\n",
    "\n",
    "    Rules:\n",
    "        1. Convert hourly rates to annual amounts. Assume a standard 40-hour work week and 52 weeks per year.\n",
    "        2. Handle salary ranges (e.g., \"$50K - $70K\") by setting both min_salary and max_salary.\n",
    "        3. Handle single values (e.g., \"Up to $80,000\" or \"$25/hour\") appropriately.\n",
    "        4. For non-numeric salaries (e.g., \"Competitive salary\"), set salary_type to 'non_numeric' and salaries to null.\n",
    "        5. Always provide a confidence score from 1 (not confident) to 10 (very confident).\n",
    "        6. If the input is empty, nonsensical, or unparsable, set salary_type to 'unknown'.\n",
    "\n",
    "    Example Input List:\n",
    "    - \"$25 an hour\"\n",
    "    - \"$50K - $70K\"\n",
    "\n",
    "    Example Output: A JSON object containing a list with two salary info objects.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def ai_parse_salaries(salary_list: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Uses the AI agent to parse a list of salary strings in a single batch operation.\n",
    "\n",
    "    Args:\n",
    "        salary_list: A list of raw salary text strings from job postings.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing parsed salary information.\n",
    "    \"\"\"\n",
    "    # Handle empty or null input list.\n",
    "    if not salary_list:\n",
    "        return []\n",
    "\n",
    "    # Format the list of strings into a single prompt for the AI.\n",
    "    formatted_list = \"\\n\".join(f\"- '{s}'\" for s in salary_list if pd.notna(s) and str(s).strip())\n",
    "    prompt = f\"Parse the following list of salary strings:\\n{formatted_list}\"\n",
    "\n",
    "    try:\n",
    "        # Make a single synchronous call to the agent for the entire batch.\n",
    "        result = _salary_agent.run_sync(prompt)\n",
    "\n",
    "        # Convert the list of Pydantic models from the result into a list of dictionaries.\n",
    "        return [s.model_dump() for s in result.output.salaries]\n",
    "    except Exception as e:\n",
    "        print(f\"AI batch parsing error: {e}\")\n",
    "        # Return a list of error objects matching the input length\n",
    "        return [{'min_salary': None, 'max_salary': None, 'salary_type': 'error', 'confidence': 1}] * len(salary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from workshoplib.janitor import ai_parse_salaries, traditional_parse_salaries\n",
    "\n",
    "print(\"âœ… Janitor module updated successfully!\")\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"  â€¢ traditional_parse_salaries (rule-based batch processing)\")\n",
    "print(\"  â€¢ ai_parse_salaries (AI-powered batch processing)\")\n",
    "\n",
    "# Quick test with sample data\n",
    "test_salaries = [\"$75,000 per year\", \"$30 an hour\", \"Competitive salary\"]\n",
    "\n",
    "print(f\"\\nTesting with: {test_salaries}\")\n",
    "traditional_results = traditional_parse_salaries(test_salaries)\n",
    "ai_results = ai_parse_salaries(test_salaries)\n",
    "\n",
    "print(\"\\nTraditional results: \")\n",
    "pp.pprint(traditional_results, compact=True, width=80)\n",
    "\n",
    "print(\"\\nAI results: \")\n",
    "pp.pprint(ai_results, compact=True, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "**Technical Skills:**\n",
    "- âœ… **Data Assessment** - Identified the messiness in real-world scraped data\n",
    "- âœ… **Traditional Parsing** - Built rule-based salary parsing logic\n",
    "- âœ… **AI Setup** - Configured PydanticAI with Google Gemini\n",
    "- âœ… **AI-Powered Parsing** - Created intelligent salary parsing with confidence scores\n",
    "- âœ… **Code Organization** - Saved reusable functions to workshoplib\n",
    "\n",
    "**Key Insights:**\n",
    "- Real-world data is always messy and needs cleaning\n",
    "- Traditional approaches require extensive edge case handling\n",
    "- AI can handle complexity and provide confidence scores\n",
    "- Structured outputs make AI results more reliable\n",
    "\n",
    "### Looking Ahead to Chapter 2\n",
    "\n",
    "In Chapter 2, we will:\n",
    "- Load both Indeed and OEWS datasets\n",
    "- Use AI to match messy job titles to official BLS categories\n",
    "- Create intelligent matching functions\n",
    "- Add these tools to our janitor module\n",
    "\n",
    "The foundation we've built here will make Chapter 2 much smoother!\n",
    "\n",
    "---\n",
    "\n",
    "*Ready for Chapter 2: AI-Powered Job Title Matching*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql",
   "formats": "ipynb,md",
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-kernelspec,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
