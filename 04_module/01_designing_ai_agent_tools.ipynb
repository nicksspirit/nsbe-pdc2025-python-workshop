{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Chapter 1: Designing the AI Agent's Tools\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will:\n",
    "- Understand the concept of AI agents and tool-based problem solving\n",
    "- Build specialized functions that an AI agent can use\n",
    "- Create a resume skill extraction tool using PydanticAI\n",
    "- Develop a job matching algorithm with scoring\n",
    "- Learn best practices for designing AI agent tools\n",
    "\n",
    "## Introduction to AI Agents and Tools\n",
    "\n",
    "> **Instructor Cue:** Start with the big picture: \"We're building the final piece of our workshop - an AI agent that can read a resume and find the best matching job. Ask the audience: What would such a system need to do?\"\n",
    "\n",
    "An AI agent is a system that can autonomously perform tasks by using available tools. Think of it like a smart assistant that can:\n",
    "\n",
    "- **Understand** what you're asking for\n",
    "- **Choose** the right tools for the job\n",
    "- **Execute** those tools in the correct sequence\n",
    "- **Combine** results to give you a final answer\n",
    "\n",
    "### Our Goal: Resume-to-Job Matching Agent\n",
    "\n",
    "Today we're building an agent that solves this problem:\n",
    "1. **Input**: A resume (as text)\n",
    "2. **Process**: Extract skills and match against job database\n",
    "3. **Output**: The best matching job opportunity\n",
    "\n",
    "> **Instructor Cue:** Draw this on a whiteboard or screen: Resume â†’ Extract Skills â†’ Score Jobs â†’ Best Match. This visual helps students understand the workflow.\n",
    "\n",
    "### Breaking Down the Problem\n",
    "\n",
    "To solve this complex problem, we'll create two specialized tools:\n",
    "\n",
    "1. **Skill Extraction Tool**: Reads resume text and identifies key technical skills\n",
    "2. **Job Matching Tool**: Compares skills against job postings and calculates match scores\n",
    "\n",
    "> **Instructor Cue:** Emphasize that breaking complex problems into smaller, manageable functions is a fundamental programming principle. Each tool has a single, clear responsibility.\n",
    "\n",
    "## Setting Up Our Tools Framework\n",
    "\n",
    "### Installing Required Dependencies\n",
    "\n",
    "Before we start coding, let's make sure we have all the necessary packages installed:\n",
    "\n",
    "> **Instructor Cue:** Have everyone run these installation commands first. Explain that we're using Google's latest Gemini 2.5 Flash model which is free and has generous usage limits. We use `uv` for fast package management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app/tools.py\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.google import GoogleModel\n",
    "from pydantic_ai.providers.google import GoogleProvider\n",
    "\n",
    "# Set up the AI model for our tools\n",
    "# Note: You'll need to set your Google API key as an environment variable\n",
    "# Using gemini-2.5-flash - Google's latest, fastest model with excellent reasoning\n",
    "provider = GoogleProvider(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = GoogleModel('gemini-2.5-flash')\n",
    "\n",
    "# Create our agent instance\n",
    "agent = Agent(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Explain environment variables and API key setup. Show how to set GOOGLE_API_KEY in the terminal or use a .env file. You can get your API key from https://aistudio.google.com/app/apikey.\n",
    "\n",
    "**Why Google Gemini 2.5 Flash?**\n",
    "- **Free tier**: 15 requests per minute, 1500 requests per day - generous for learning\n",
    "- **Latest model**: Gemini 2.5 Flash is Google's newest, fastest model with improved reasoning\n",
    "- **Excellent text analysis**: Specifically strong at extracting structured information from unstructured text\n",
    "- **Enhanced performance**: Better accuracy and speed compared to previous versions\n",
    "- **Easy integration**: Works seamlessly with PydanticAI framework\n",
    "- **No credit card required**: Perfect for workshops and learning environments\n",
    "\n",
    "> **Instructor Cue:** Emphasize security - never hardcode API keys! Always use environment variables or secure secret management.\n",
    "\n",
    "## Tool 1: Skill Extraction from Resume\n",
    "\n",
    "Our first tool will use AI to extract technical skills from resume text. This is perfect for AI because it requires understanding context and identifying relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app/tools.py\n",
    "\n",
    "# <START> EXTRACT SKILLS\n",
    "\n",
    "def extract_skills_from_resume(resume_text: str, top_n: int = 10) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract the top technical skills from a resume using AI.\n",
    "\n",
    "    Args:\n",
    "        resume_text (str): The full text content of a resume\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of the most important technical skills found\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a focused prompt for skill extraction\n",
    "    prompt = f\"\"\"\n",
    "    Please analyze this resume and extract the top {top_n} most important technical skills.\n",
    "    Focus on:\n",
    "    - Programming languages (Python, JavaScript, etc.)\n",
    "    - Frameworks and libraries (React, Django, etc.)\n",
    "    - Tools and technologies (Git, Docker, AWS, etc.)\n",
    "    - Data analysis tools (Pandas, SQL, etc.)\n",
    "    - Any other technical competencies\n",
    "\n",
    "    Return only the skill names, one per line, without explanations.\n",
    "    Be specific (e.g., \"Python\" not \"programming languages\").\n",
    "\n",
    "    Resume text:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the agent to process the prompt\n",
    "    result = agent.run_sync(prompt)\n",
    "    skills_text = result.output\n",
    "\n",
    "    # Split by lines and clean up\n",
    "    skills = [\n",
    "        skill.strip().strip('-â€¢*').strip()\n",
    "        for skill in skills_text.split('\\n')\n",
    "        if skill.strip() and len(skill.strip()) > 1\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates while preserving order\n",
    "    unique_skills = set(skill.lower() for skill in skills)\n",
    "\n",
    "    return list(unique_skills)[:top_n]  # Return top N skills\n",
    "\n",
    "# <END> EXTRACT SKILLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Walk through this function step by step. Explain the prompt engineering - how we give specific instructions to get better results. Point out the error handling and fallback mechanism. This is real-world code!\n",
    "\n",
    "## Testing the Skill Extraction Tool\n",
    "\n",
    "Let's test our skill extraction with the sample resume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def test_skill_extraction():\n",
    "    \"\"\"Test function to verify our skill extraction works\"\"\"\n",
    "\n",
    "    sample_resume = Path(\"data/sample_resume.txt\").read_text()\n",
    "\n",
    "    print(\"Sample Resume Text:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(sample_resume[:300] + \"...\" if len(sample_resume) > 300 else sample_resume)\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "    # Extract skills\n",
    "    print(\"Extracting skills...\")\n",
    "    skills = extract_skills_from_resume(sample_resume, 10)\n",
    "\n",
    "    print(f\"\\nExtracted Skills ({len(skills)}):\")\n",
    "    for i, skill in enumerate(skills, 1):\n",
    "        print(f\"{i}. {skill}\")\n",
    "\n",
    "\n",
    "# test_skill_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Run this test function live to demonstrate the skill extraction. If API calls fail, use this as a teaching moment about error handling and fallback mechanisms.\n",
    "\n",
    "## Tool 2: Job Matching Algorithm\n",
    "\n",
    "Our second tool will score job postings against extracted skills to find the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app/tools.py\n",
    "\n",
    "# <START> JOB MATCHING\n",
    "\n",
    "def find_best_job_match(skills: list[str], jobs_df: pd.DataFrame) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find the best matching job based on extracted skills.\n",
    "\n",
    "    Args:\n",
    "        skills (list[str]): List of skills extracted from resume\n",
    "        jobs_df (pd.DataFrame): DataFrame containing job postings\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: Information about the best matching job\n",
    "    \"\"\"\n",
    "\n",
    "    if jobs_df.empty or not skills:\n",
    "        return {\n",
    "            \"error\": \"No jobs available or no skills provided\",\n",
    "            \"job_title\": \"No match found\",\n",
    "            \"company_name\": \"N/A\",\n",
    "            \"location\": \"N/A\",\n",
    "            \"match_score\": 0,\n",
    "            \"matched_skills\": []\n",
    "        }\n",
    "\n",
    "    # Note: skills are already lowercase from extract_skills_from_resume\n",
    "\n",
    "    # Calculate match scores for each job\n",
    "    job_scores = []\n",
    "\n",
    "    for index, job in jobs_df.iterrows():\n",
    "        score_info = calculate_job_score(job, skills)\n",
    "        job_scores.append({\n",
    "            'index': index,\n",
    "            'score': score_info['score'],\n",
    "            'matched_skills': score_info['matched_skills'],\n",
    "            'job_data': job\n",
    "        })\n",
    "\n",
    "    # Sort by score (highest first)\n",
    "    job_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    if not job_scores or job_scores[0]['score'] == 0:\n",
    "        return {\n",
    "            \"error\": \"No matching jobs found\",\n",
    "            \"job_title\": \"No suitable matches\",\n",
    "            \"company_name\": \"N/A\",\n",
    "            \"location\": \"N/A\",\n",
    "            \"match_score\": 0,\n",
    "            \"matched_skills\": []\n",
    "        }\n",
    "\n",
    "    # Get the best match\n",
    "    best_match = job_scores[0]\n",
    "    job_data = best_match['job_data']\n",
    "\n",
    "    return {\n",
    "        \"job_title\": job_data['job_title'],\n",
    "        \"company_name\": job_data['company_name'],\n",
    "        \"location\": job_data['location'],\n",
    "        \"salary\": job_data.get('salary', 'Not specified'),\n",
    "        \"job_description\": job_data.get('job_description', '')[:300] + \"...\",\n",
    "        \"match_score\": best_match['score'],\n",
    "        \"matched_skills\": best_match['matched_skills'],\n",
    "        \"total_jobs_analyzed\": len(job_scores)\n",
    "    }\n",
    "\n",
    "def calculate_job_score(job: pd.Series, skills: list[str]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate how well a job matches the given skills.\n",
    "\n",
    "    Args:\n",
    "        job (pd.Series): A single job posting\n",
    "        skills (list[str]): Skills (already in lowercase)\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: Score and matched skills information\n",
    "    \"\"\"\n",
    "\n",
    "    # Get job text for analysis (combine title and description)\n",
    "    job_text = \"\"\n",
    "    if pd.notna(job.get('job_title')):\n",
    "        job_text += job['job_title'].lower() + \" \"\n",
    "\n",
    "    if pd.notna(job.get('job_description')):\n",
    "        job_text += job['job_description'].lower() + \" \"\n",
    "\n",
    "    if not job_text.strip():\n",
    "        return {\"score\": 0, \"matched_skills\": []}\n",
    "\n",
    "    matched_skills = []\n",
    "    score = 0\n",
    "\n",
    "    # Check each skill against job text\n",
    "    for skill in skills:\n",
    "        if skill in job_text:\n",
    "            matched_skills.append(skill)\n",
    "\n",
    "            # Weight skills differently based on importance\n",
    "            if len(skill) <= 3:  # Short skills like \"SQL\", \"AWS\"\n",
    "                score += 2\n",
    "            elif skill in ['python', 'javascript', 'java', 'react', 'django']:\n",
    "                score += 3  # High-value skills\n",
    "            else:\n",
    "                score += 1  # Standard match\n",
    "\n",
    "    # Bonus for multiple skill matches\n",
    "    if len(matched_skills) >= 3:\n",
    "        score += 2\n",
    "    if len(matched_skills) >= 5:\n",
    "        score += 3\n",
    "\n",
    "    return {\n",
    "        \"score\": score,\n",
    "        \"matched_skills\": matched_skills\n",
    "    }\n",
    "\n",
    "# <END> JOB MATCHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Explain the scoring algorithm. Why do we weight some skills more heavily? How does the bonus system work? This teaches algorithmic thinking and business logic implementation.\n",
    "\n",
    "## Testing the Complete Tool Chain\n",
    "\n",
    "Let's create a comprehensive test that shows both tools working together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_complete_workflow():\n",
    "    \"\"\"Test the complete resume-to-job matching workflow\"\"\"\n",
    "\n",
    "    print(\"=== TESTING COMPLETE AI AGENT WORKFLOW ===\\n\")\n",
    "\n",
    "    # Step 1: Load sample resume\n",
    "    try:\n",
    "        with open(\"data/sample_resume.txt\", \"r\") as file:\n",
    "            resume_text = file.read()\n",
    "        print(\"âœ… Sample resume loaded successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Sample resume file not found\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Load job data\n",
    "    try:\n",
    "        jobs_df = pd.read_csv(\"data/indeed_jobs_combined.csv\")\n",
    "        print(f\"âœ… Job database loaded: {len(jobs_df)} jobs available\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Job data file not found\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Extract skills from resume\n",
    "    print(\"\\n--- STEP 1: SKILL EXTRACTION ---\")\n",
    "    skills = extract_skills_from_resume(resume_text)\n",
    "    print(f\"Extracted {len(skills)} skills:\")\n",
    "    for i, skill in enumerate(skills, 1):\n",
    "        print(f\"  {i}. {skill}\")\n",
    "\n",
    "    # Step 4: Find best job match\n",
    "    print(\"\\n--- STEP 2: JOB MATCHING ---\")\n",
    "    best_match = find_best_job_match(skills, jobs_df)\n",
    "\n",
    "    if \"error\" in best_match:\n",
    "        print(f\"âŒ {best_match['error']}\")\n",
    "        return\n",
    "\n",
    "    # Step 5: Display results\n",
    "    print(\"\\n--- FINAL RESULTS ---\")\n",
    "    print(\"ðŸŽ¯ Best Job Match Found!\")\n",
    "    print(f\"ðŸ“‹ Position: {best_match['job_title']}\")\n",
    "    print(f\"ðŸ¢ Company: {best_match['company_name']}\")\n",
    "    print(f\"ðŸ“ Location: {best_match['location']}\")\n",
    "    print(f\"ðŸ’° Salary: {best_match['salary']}\")\n",
    "    print(f\"â­ Match Score: {best_match['match_score']}\")\n",
    "    print(f\"ðŸ” Jobs Analyzed: {best_match['total_jobs_analyzed']}\")\n",
    "\n",
    "    print(f\"\\nðŸŽ¯ Matched Skills ({len(best_match['matched_skills'])}):\")\n",
    "    for skill in best_match[\"matched_skills\"]:\n",
    "        print(f\"  âœ“ {skill}\")\n",
    "\n",
    "    print(\"\\nðŸ“ Job Description Preview:\")\n",
    "    print(best_match[\"job_description\"])\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "# Uncomment to test the complete workflow:\n",
    "# test_complete_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Run this test live if possible. If not, walk through what each step would produce. This shows the complete workflow from input to output.\n",
    "\n",
    "## Enhancing Our Tools\n",
    "\n",
    "Let's add some improvements to make our tools more robust and useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app/tools.py\n",
    "\n",
    "# <START> ADDITIONAL TOOLS\n",
    "\n",
    "def get_skill_statistics(skills: list[str], jobs_df: pd.DataFrame) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze how common each skill is in the job market.\n",
    "\n",
    "    Args:\n",
    "        skills (list[str]): List of skills to analyze\n",
    "        jobs_df (pd.DataFrame): Job postings database\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: Statistics about skill demand\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine all job text for analysis\n",
    "    all_job_text = \"\"\n",
    "    for _, job in jobs_df.iterrows():\n",
    "        if pd.notna(job.get('job_description')):\n",
    "            all_job_text += job['job_description'].lower() + \" \"\n",
    "        if pd.notna(job.get('job_title')):\n",
    "            all_job_text += job['job_title'].lower() + \" \"\n",
    "\n",
    "    skill_stats = {}\n",
    "    total_jobs = len(jobs_df)\n",
    "\n",
    "    for skill in skills:\n",
    "        skill_lower = skill.lower()\n",
    "\n",
    "        # Count jobs mentioning this skill\n",
    "        job_count = 0\n",
    "        for _, job in jobs_df.iterrows():\n",
    "            job_text = \"\"\n",
    "            if pd.notna(job.get('job_description')):\n",
    "                job_text += job['job_description'].lower() + \" \"\n",
    "            if pd.notna(job.get('job_title')):\n",
    "                job_text += job['job_title'].lower() + \" \"\n",
    "\n",
    "            if skill_lower in job_text:\n",
    "                job_count += 1\n",
    "\n",
    "        skill_stats[skill] = {\n",
    "            'jobs_mentioning': job_count,\n",
    "            'percentage': round((job_count / total_jobs) * 100, 1) if total_jobs > 0 else 0,\n",
    "            'demand_level': get_demand_level(job_count, total_jobs)\n",
    "        }\n",
    "\n",
    "    return skill_stats\n",
    "\n",
    "def get_demand_level(job_count: int, total_jobs: int) -> str:\n",
    "    \"\"\"Categorize skill demand level\"\"\"\n",
    "    if total_jobs == 0:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    percentage = (job_count / total_jobs) * 100\n",
    "\n",
    "    if percentage >= 50:\n",
    "        return \"Very High\"\n",
    "    elif percentage >= 25:\n",
    "        return \"High\"\n",
    "    elif percentage >= 10:\n",
    "        return \"Medium\"\n",
    "    elif percentage >= 5:\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Very Low\"\n",
    "\n",
    "def find_alternative_matches(skills: list[str], jobs_df: pd.DataFrame, top_n: int = 5) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Find multiple good job matches, not just the best one.\n",
    "\n",
    "    Args:\n",
    "        skills (list[str]): List of skills from resume\n",
    "        jobs_df (pd.DataFrame): Job postings database\n",
    "        top_n (int): Number of top matches to return\n",
    "\n",
    "    Returns:\n",
    "        list[dict[str, Any]]: Top N matching jobs\n",
    "    \"\"\"\n",
    "\n",
    "    if jobs_df.empty or not skills:\n",
    "        return []\n",
    "\n",
    "    skills_lower = [skill.lower() for skill in skills]\n",
    "    job_scores = []\n",
    "\n",
    "    # Calculate scores for all jobs\n",
    "    for index, job in jobs_df.iterrows():\n",
    "        score_info = calculate_job_score(job, skills_lower)\n",
    "\n",
    "        if score_info['score'] > 0:  # Only include jobs with some match\n",
    "            job_scores.append({\n",
    "                'job_title': job['job_title'],\n",
    "                'company_name': job['company_name'],\n",
    "                'location': job['location'],\n",
    "                'salary': job.get('salary', 'Not specified'),\n",
    "                'match_score': score_info['score'],\n",
    "                'matched_skills': score_info['matched_skills']\n",
    "            })\n",
    "\n",
    "    # Sort and return top N\n",
    "    job_scores.sort(key=lambda x: x['match_score'], reverse=True)\n",
    "    return job_scores[:top_n]\n",
    "\n",
    "# <END> ADDITIONAL TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Explain how these enhancement functions provide more insight. The skill statistics help understand market demand, and alternative matches give users more options.\n",
    "\n",
    "## Error Handling and Edge Cases\n",
    "\n",
    "Good tools must handle various edge cases gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app/tools.py\n",
    "\n",
    "# <START> Error Handling\n",
    "\n",
    "def validate_resume_text(resume_text: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate that resume text is suitable for processing.\n",
    "\n",
    "    Args:\n",
    "        resume_text (str): Resume text to validate\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: Validation results and suggestions\n",
    "    \"\"\"\n",
    "\n",
    "    issues = []\n",
    "    warnings = []\n",
    "\n",
    "    # Check basic requirements\n",
    "    if not resume_text or not resume_text.strip():\n",
    "        issues.append(\"Resume text is empty\")\n",
    "        return {\"valid\": False, \"issues\": issues, \"warnings\": warnings}\n",
    "\n",
    "    # Check length\n",
    "    word_count = len(resume_text.split())\n",
    "    if word_count < 50:\n",
    "        warnings.append(\"Resume seems quite short - consider adding more detail\")\n",
    "    elif word_count > 2000:\n",
    "        warnings.append(\"Resume is very long - extraction might focus on early sections\")\n",
    "\n",
    "    # Check for common sections\n",
    "    resume_lower = resume_text.lower()\n",
    "    expected_sections = ['experience', 'skills', 'education', 'work']\n",
    "    found_sections = [section for section in expected_sections if section in resume_lower]\n",
    "\n",
    "    if len(found_sections) < 2:\n",
    "        warnings.append(\"Resume might be missing common sections (experience, skills, education)\")\n",
    "\n",
    "    # Check for technical content\n",
    "    tech_indicators = ['python', 'javascript', 'programming', 'software', 'development', 'technical']\n",
    "    tech_mentions = sum(1 for indicator in tech_indicators if indicator in resume_lower)\n",
    "\n",
    "    if tech_mentions == 0:\n",
    "        warnings.append(\"No technical skills detected - results may be limited\")\n",
    "\n",
    "    return {\n",
    "        \"valid\": True,\n",
    "        \"word_count\": word_count,\n",
    "        \"sections_found\": found_sections,\n",
    "        \"tech_indicators\": tech_mentions,\n",
    "        \"issues\": issues,\n",
    "        \"warnings\": warnings\n",
    "    }\n",
    "\n",
    "def safe_extract_skills(resume_text: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Safely extract skills with comprehensive error handling.\n",
    "\n",
    "    Args:\n",
    "        resume_text (str): Resume text to process\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: Results including skills and any issues\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input\n",
    "    validation = validate_resume_text(resume_text)\n",
    "\n",
    "    if not validation[\"valid\"]:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"skills\": [],\n",
    "            \"issues\": validation[\"issues\"],\n",
    "            \"warnings\": validation[\"warnings\"]\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        # Attempt skill extraction\n",
    "        skills = extract_skills_from_resume(resume_text)\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"skills\": skills,\n",
    "            \"skill_count\": len(skills),\n",
    "            \"word_count\": validation[\"word_count\"],\n",
    "            \"issues\": validation[\"issues\"],\n",
    "            \"warnings\": validation[\"warnings\"]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"skills\": [],\n",
    "            \"error\": str(e),\n",
    "            \"issues\": validation[\"issues\"] + [f\"Processing error: {str(e)}\"],\n",
    "            \"warnings\": validation[\"warnings\"]\n",
    "        }\n",
    "\n",
    "# <END> ADDITIONAL TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Emphasize that production code needs robust error handling. These functions make our tools more reliable and provide helpful feedback to users.\n",
    "\n",
    "## Exercise: Test and Customize Your Tools\n",
    "\n",
    "> **Instructor Cue:** Give participants 15 minutes to test and experiment with the tools:\n",
    "\n",
    "Try these exercises to explore your tools:\n",
    "\n",
    "1. **Test with Different Resume Content:**\n",
    "   - Modify the sample resume\n",
    "   - Try a resume focused on a different field\n",
    "   - Test with very short or very long text\n",
    "\n",
    "2. **Experiment with Scoring:**\n",
    "   - Adjust the scoring weights in `calculate_job_score()`\n",
    "   - Add bonus points for specific skills\n",
    "   - Try different matching strategies\n",
    "\n",
    "3. **Analyze Skill Demand:**\n",
    "   - Use `get_skill_statistics()` to see which skills are most in demand\n",
    "   - Compare different skill sets\n",
    "\n",
    "4. **Test Edge Cases:**\n",
    "   - Empty resume text\n",
    "   - Resume with no technical skills\n",
    "   - Very technical resume\n",
    "\n",
    "## Key Concepts Learned\n",
    "\n",
    "> **Instructor Cue:** Summarize the important concepts from this chapter:\n",
    "\n",
    "1. **Tool-Based Problem Solving**: Breaking complex tasks into specialized functions\n",
    "2. **AI Integration**: Using language models for text analysis and extraction\n",
    "3. **Scoring Algorithms**: Quantifying matches between different data sets\n",
    "4. **Error Handling**: Building robust tools that handle edge cases gracefully\n",
    "5. **Validation**: Ensuring input data meets quality requirements\n",
    "\n",
    "## Best Practices for AI Agent Tools\n",
    "\n",
    "> **Instructor Cue:** Share these guidelines for building effective AI tools:\n",
    "\n",
    "1. **Single Responsibility**: Each tool should do one thing well\n",
    "2. **Clear Interfaces**: Well-defined inputs and outputs\n",
    "3. **Error Resilience**: Graceful handling of failures with fallback options\n",
    "4. **Testability**: Easy to test with different inputs\n",
    "5. **Documentation**: Clear explanations of what each tool does\n",
    "\n",
    "## Troubleshooting Common Issues\n",
    "\n",
    "> **Instructor Cue:** Keep this section handy for addressing problems:\n",
    "\n",
    "**API Connection Issues:**\n",
    "- Check Google API key is set correctly\n",
    "- Verify internet connection\n",
    "- Try the fallback skill extraction\n",
    "\n",
    "**Skill Extraction Problems:**\n",
    "- Resume text might be too short or unstructured\n",
    "- AI model might be overloaded (use fallback)\n",
    "- Check for special characters or encoding issues\n",
    "\n",
    "**Job Matching Issues:**\n",
    "- Verify job data is loaded correctly\n",
    "- Check that skills list is not empty\n",
    "- Ensure job descriptions contain meaningful text\n",
    "\n",
    "**Performance Issues:**\n",
    "- Large datasets might be slow to process\n",
    "- Consider sampling jobs for faster testing\n",
    "- Cache results when possible\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "> **Instructor Cue:** Build excitement for the final chapter:\n",
    "\n",
    "In the next chapter, we'll integrate these tools into a beautiful Streamlit interface that brings everything together:\n",
    "\n",
    "- **Interactive Resume Input**: Users can paste their resume directly\n",
    "- **Real-time Skill Extraction**: See skills extracted instantly\n",
    "- **Dynamic Job Matching**: Find matches with visual feedback\n",
    "- **Professional Results Display**: Beautiful presentation of results\n",
    "- **Enhanced Features**: Skill demand analysis and alternative matches\n",
    "\n",
    "Our tools are the engine - next we'll build the user interface that makes them accessible to everyone!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "> **Instructor Cue:** Remind students to save their complete tools.py file - they'll need it for the next chapter!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql",
   "formats": "ipynb,md",
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-kernelspec,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "nsbe-pdc2025-python-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
